{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from game import game, random_connection_game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Memb = 400\n",
    "newg = random_connection_game(9,  Memb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00 -0.09 -0.11 0.00 -0.05 0.04 0.00 -0.06 -0.02 \n",
      "-0.09 0.13 0.11 0.08 -0.07 0.00 0.00 -0.04 -0.05 \n",
      "-0.11 0.11 -0.08 -0.16 0.00 -0.05 0.02 0.00 -0.02 \n",
      "0.00 0.08 -0.16 0.06 -0.24 0.15 0.03 -0.04 0.00 \n",
      "-0.05 -0.07 0.00 -0.24 -0.16 -0.08 0.12 -0.04 0.00 \n",
      "0.04 0.00 -0.05 0.15 -0.08 0.00 0.00 0.02 -0.08 \n",
      "0.00 0.00 0.02 0.03 0.12 0.00 -0.05 -0.19 0.10 \n",
      "-0.06 -0.04 0.00 -0.04 -0.04 0.02 -0.19 0.10 0.05 \n",
      "-0.02 -0.05 -0.02 0.00 0.00 -0.08 0.10 0.05 0.00 \n"
     ]
    }
   ],
   "source": [
    "newg.print_original()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00 -0.09 -0.11 0.00 -0.05 0.04 0.00 -0.06 -0.02 \n",
      "-0.09 0.13 0.11 0.08 -0.07 0.00 0.00 -0.04 -0.05 \n",
      "-0.11 0.11 -0.08 -0.16 0.00 -0.05 0.02 0.00 -0.02 \n",
      "0.00 0.08 -0.16 0.06 -0.24 0.15 0.03 -0.04 0.00 \n",
      "-0.05 -0.07 0.00 -0.24 -0.16 -0.08 0.12 -0.04 0.00 \n",
      "0.04 0.00 -0.05 0.15 -0.08 0.00 0.00 0.02 -0.08 \n",
      "0.00 0.00 0.02 0.03 0.12 0.00 -0.05 -0.19 0.10 \n",
      "-0.06 -0.04 0.00 -0.04 -0.04 0.02 -0.19 0.10 0.05 \n",
      "-0.02 -0.05 -0.02 0.00 0.00 -0.08 0.10 0.05 0.00 \n"
     ]
    }
   ],
   "source": [
    "newg.print_original()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 400, 400)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newg.state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomAgent(state, Memb = 25):\n",
    "    move = random.randint(3)\n",
    "    spin_1 = random.randint(Memb)\n",
    "    spin_2 = random.randint(4)\n",
    "    return (move, spin_1, spin_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.dqn_agent import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.model import QNetwork_Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset!\n",
    "Memb = 6*6\n",
    "statesize = Memb*Memb*1+9*9\n",
    "actionsize = 3*Memb*4\n",
    "randomAgent0 = lambda state: randomAgent(state, Memb)\n",
    "#env = game(Hint, Memb = Memb)\n",
    "smartagent0 = Agent(statesize, actionsize, seed = 1,\n",
    "                    embedding_size = Memb, neighbours = 4,\n",
    "                   nu = [32, 64, 128, 128, 64, 64], model = QNetwork_Conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = random_connection_game(9,  Memb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 36, 36)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10.25 19 (2, 19, 3) 15\n"
     ]
    }
   ],
   "source": [
    "env = random_connection_game(9,  Memb, \n",
    "                             max_consecutive_failures = 50)\n",
    "env.reset()\n",
    "#\n",
    "state = env.state\n",
    "fig, ax = env.plot()\n",
    "score = 0.0\n",
    "actions = []\n",
    "for j in range(2000):\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    action = smartagent0.act(state, eps = 1.0)\n",
    "    state, reward, done =env.step(action)\n",
    "    score += reward\n",
    "    actions.append((*action, reward))\n",
    "\n",
    "    fig, ax = env.plot()\n",
    "    plt.show()\n",
    "    print(score, env.N, action, env.terms_left)\n",
    "    if done >0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = env.reset()\n",
    "env.nS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, deque\n",
    "\n",
    "def dqn(agent, n_episodes=2000, max_t=2000, \n",
    "        eps_start=1.0, eps_end=0.01, eps_decay=0.999):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        state = env.reset()\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state, eps)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            action_tr = action[0]+action[1]*3+action[2]*3*Memb\n",
    "            agent.step(state, action_tr, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break \n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score, eps: {:.2f}, {:.2f}'.format(i_episode, np.mean(scores_window), eps))\n",
    "        if np.mean(scores_window)>=3.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            torch.save(agent.qnetwork_online.state_dict(), 'checkpoint.pth')\n",
    "            break\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score, eps: -10.54, 0.90\n",
      "Episode 200\tAverage Score, eps: -10.26, 0.82\n",
      "Episode 263\tAverage Score: -10.41"
     ]
    }
   ],
   "source": [
    "scores = dqn(smartagent0, n_episodes=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Memb = 6*6\n",
    "env = random_connection_game(9,  Memb, \n",
    "                             max_consecutive_failures = 50)\n",
    "\n",
    "state = env.reset()\n",
    "fig, ax = env.plot()\n",
    "score = 0.0\n",
    "actions = []\n",
    "for j in range(2000):\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    action = smartagent0.act(state, eps = 1.0)\n",
    "    state, reward, done =env.step(action)\n",
    "    score += reward\n",
    "    actions.append((*action, reward))\n",
    "\n",
    "    fig, ax = env.plot()\n",
    "    plt.show()\n",
    "    print(score, env.N, action, env.terms_left)\n",
    "    if done >0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
